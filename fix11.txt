Problem: pdfjs-dist import is failing with TypeError: s is not a function due to incorrect module import in Next.js client components.

Solution: Use the correct import path for pdfjs-dist in a browser/client environment.

File: lib/pdfExtractor.ts

Replace the entire file with:

'use client';

export async function extractTextFromPDF(file: File): Promise<string> {
  try {
    // Dynamically import pdfjs-dist to avoid SSR issues
    const pdfjsLib = await import('pdfjs-dist/build/pdf.mjs');
    
    // Set up worker - use fake worker (no external file needed)
    const pdfjsWorker = await import('pdfjs-dist/build/pdf.worker.mjs');
    pdfjsLib.GlobalWorkerOptions.workerSrc = pdfjsWorker;

    const arrayBuffer = await file.arrayBuffer();
    const uint8Array = new Uint8Array(arrayBuffer);
    
    // Load PDF document
    const loadingTask = pdfjsLib.getDocument({
      data: uint8Array,
    });
    
    const pdf = await loadingTask.promise;
    const textParts: string[] = [];
    
    // Extract text from each page
    for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
      const page = await pdf.getPage(pageNum);
      const textContent = await page.getTextContent();
      
      const pageText = textContent.items
        .filter((item: any) => 'str' in item)
        .map((item: any) => item.str)
        .join(' ');
      
      textParts.push(pageText);
    }
    
    const fullText = textParts.join('\n\n').trim();
    
    if (!fullText || fullText.length < 20) {
      throw new Error('No readable text found in PDF. It may be scanned/image-based.');
    }
    
    return fullText;
    
  } catch (error: any) {
    console.error('PDF extraction error:', error);
    throw error;
  }
}
If the above still fails, try this alternative approach using a different import method:

File: lib/pdfExtractor.ts

'use client';

export async function extractTextFromPDF(file: File): Promise<string> {
  try {
    // Read file as array buffer
    const arrayBuffer = await file.arrayBuffer();
    
    // Use dynamic import with specific path for browser
    const pdfjs = await import('pdfjs-dist');
    
    // Disable worker entirely - single threaded mode
    pdfjs.GlobalWorkerOptions.workerSrc = '';
    
    // Create typed array from buffer
    const typedArray = new Uint8Array(arrayBuffer);
    
    // Load the PDF
    const pdf = await pdfjs.getDocument({
      data: typedArray,
      disableWorker: true,
      isEvalSupported: false,
    }).promise;
    
    let fullText = '';
    
    // Loop through each page
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      
      const strings = content.items
        .map((item: any) => {
          if (typeof item === 'object' && 'str' in item) {
            return item.str;
          }
          return '';
        })
        .filter(Boolean);
      
      fullText += strings.join(' ') + '\n\n';
    }
    
    fullText = fullText.trim();
    
    if (!fullText || fullText.length < 20) {
      throw new Error('Could not extract text. PDF may be image-based.');
    }
    
    return fullText;
    
  } catch (error: any) {
    console.error('PDF extraction failed:', error);
    throw new Error('Failed to extract text from PDF: ' + (error.message || 'Unknown error'));
  }
}
If pdfjs-dist continues to fail, use this bulletproof alternative with a different library:

Step 1: Install pdf2json or use the fetch API to send to server

Actually, let's try the simplest possible approach - send the PDF to the server and use a Node.js compatible library:

Step 1: Update package.json to use an older, more stable version of pdf-parse:

npm uninstall pdfjs-dist
npm install pdf-parse@1.1.1
Step 2: File: app/api/extract-text/route.ts

import { NextRequest, NextResponse } from 'next/server';

export async function POST(req: NextRequest) {
  try {
    const formData = await req.formData();
    const file = formData.get('file') as File;

    if (!file) {
      return NextResponse.json({ error: 'No file provided' }, { status: 400 });
    }

    const fileName = file.name.toLowerCase();
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    let text = '';

    if (fileName.endsWith('.txt')) {
      text = buffer.toString('utf-8');
      
    } else if (fileName.endsWith('.docx')) {
      const mammoth = await import('mammoth');
      const result = await mammoth.extractRawText({ buffer });
      text = result.value;
      
    } else if (fileName.endsWith('.pdf')) {
      // Use pdf-parse for server-side PDF extraction
      const pdf = require('pdf-parse');
      const data = await pdf(buffer);
      text = data.text;
      
    } else {
      return NextResponse.json(
        { error: 'Unsupported format. Use PDF, DOCX, or TXT.' },
        { status: 400 }
      );
    }

    // Clean text
    text = text.replace(/\s+/g, ' ').replace(/\n{3,}/g, '\n\n').trim();

    if (!text || text.length < 20) {
      return NextResponse.json(
        { error: 'Could not extract text from file.' },
        { status: 400 }
      );
    }

    return NextResponse.json({ success: true, text });
    
  } catch (error: any) {
    console.error('Extraction error:', error);
    return NextResponse.json(
      { error: 'Failed to process file: ' + error.message },
      { status: 500 }
    );
  }
}
Step 3: Update frontend to always use server-side extraction:

In app/linkedin-optimizer/page.tsx and app/interview-prep/page.tsx:

const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
  const file = e.target.files?.[0];
  if (!file) return;

  setResumeFile(file);
  setError('');

  const formData = new FormData();
  formData.append('file', file);

  try {
    const response = await fetch('/api/extract-text', {
      method: 'POST',
      body: formData,
    });

    const data = await response.json();

    if (response.ok && data.success) {
      setResumeContent(data.text);
    } else {
      setError(data.error || 'Failed to extract text from file');
    }
  } catch (err: any) {
    console.error('Upload error:', err);
    setError('Failed to process file. Please try again.');
  }
};
Step 4: Create a postinstall script to fix pdf-parse test folder issue:

File: scripts/fix-pdf-parse.js

const fs = require('fs');
const path = require('path');

const testDir = path.join(__dirname, '..', 'node_modules', 'pdf-parse', 'test');
const testFile = path.join(testDir, 'data', 'test.pdf');

// Create test directory if it doesn't exist
if (!fs.existsSync(path.join(testDir, 'data'))) {
  fs.mkdirSync(path.join(testDir, 'data'), { recursive: true });
}

// Create empty test file if it doesn't exist
if (!fs.existsSync(testFile)) {
  fs.writeFileSync(testFile, '');
}

console.log('pdf-parse test directory fixed');
Update package.json:

{
  "scripts": {
    "postinstall": "node scripts/fix-pdf-parse.js",
    // ... other scripts
  }
}
Git commands:

npm uninstall pdfjs-dist
npm install pdf-parse@1.1.1
mkdir -p scripts
# Create the fix-pdf-parse.js file
node scripts/fix-pdf-parse.js
git add .
git commit -m "Fix: Use pdf-parse for server-side PDF extraction with postinstall fix"
git push origin main
This server-side approach with pdf-parse and the postinstall fix is the most reliable solution for Vercel deployments. Many production apps use this exact setup.